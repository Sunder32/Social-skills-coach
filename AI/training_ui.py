"""
Gradio Training Interface
Web UI for training and managing the Social Skills Model
"""
import gradio as gr
import torch
import os
import json
import threading
from datetime import datetime
from typing import Optional
import traceback

# Import training components
from config import config
from core.model import SocialSkillsModel
from core.llm_client import LLMClient
from training.trainer import SFTTrainer
from training.dpo_trainer import DPOTrainer
from training.dataset import ConversationDataset, PreferenceDataset, create_sample_data


# Global state
training_state = {
    "is_training": False,
    "progress": 0,
    "current_step": 0,
    "total_steps": 0,
    "loss": 0,
    "status": "–ì–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é",
    "logs": []
}

model = None
tokenizer = None


def log_message(message: str):
    """Add message to logs"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    training_state["logs"].append(f"[{timestamp}] {message}")
    # Keep only last 100 logs
    training_state["logs"] = training_state["logs"][-100:]


def get_model_info():
    """Get information about current model"""
    global model
    
    model_path = config.model.model_path
    
    info = {
        "–°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏": "–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞",
        "–ü—É—Ç—å": model_path,
        "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã": "-",
        "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ": config.training.device,
        "GPU –¥–æ—Å—Ç—É–ø–µ–Ω": torch.cuda.is_available()
    }
    
    if os.path.exists(model_path):
        info["–°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏"] = "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –Ω–∞ –¥–∏—Å–∫–µ"
        
        config_path = os.path.join(model_path, "config.json")
        if os.path.exists(config_path):
            with open(config_path) as f:
                model_config = json.load(f)
            info["Hidden size"] = model_config.get("hidden_size", "-")
            info["Layers"] = model_config.get("num_layers", "-")
            info["Heads"] = model_config.get("num_heads", "-")
    
    if model is not None:
        info["–°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏"] = "–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ –ø–∞–º—è—Ç—å"
        info["–ü–∞—Ä–∞–º–µ—Ç—Ä—ã"] = f"{model.get_num_params():,}"
        info["Trainable"] = f"{model.get_num_trainable_params():,}"
    
    return "\n".join([f"**{k}:** {v}" for k, v in info.items()])


def load_model_handler():
    """Load model into memory"""
    global model, tokenizer
    
    try:
        from transformers import AutoTokenizer
        
        log_message("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        
        model_path = config.model.model_path
        
        if os.path.exists(model_path):
            model = SocialSkillsModel.from_pretrained(
                model_path, 
                device=config.training.device if torch.cuda.is_available() else "cpu"
            )
            tokenizer = AutoTokenizer.from_pretrained(config.model.tokenizer_path)
        else:
            log_message("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é...")
            model = SocialSkillsModel(
                vocab_size=config.model.vocab_size,
                hidden_size=config.model.hidden_size,
                num_layers=config.model.num_layers,
                num_heads=config.model.num_heads,
                max_length=config.model.max_length
            )
            
            device = config.training.device if torch.cuda.is_available() else "cpu"
            model.to(device)
            
            # Load tokenizer
            tokenizer = AutoTokenizer.from_pretrained("ai-forever/rugpt3small_based_on_gpt2")
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
        
        log_message(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {model.get_num_params():,}")
        return get_model_info(), "\n".join(training_state["logs"])
    
    except Exception as e:
        log_message(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        return get_model_info(), "\n".join(training_state["logs"])


def create_sample_data_handler():
    """Create sample training data"""
    try:
        sft_path, pref_path = create_sample_data(config.data_dir)
        log_message(f"–°–æ–∑–¥–∞–Ω—ã –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
        log_message(f"  SFT: {sft_path}")
        log_message(f"  DPO: {pref_path}")
        return "\n".join(training_state["logs"])
    except Exception as e:
        log_message(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return "\n".join(training_state["logs"])


def progress_callback(step, total, metrics):
    """Update training progress"""
    training_state["current_step"] = step
    training_state["total_steps"] = total
    training_state["progress"] = int(step / total * 100) if total > 0 else 0
    training_state["loss"] = metrics.get("loss", 0)


def train_sft_handler(
    data_path: str,
    num_epochs: int,
    batch_size: int,
    learning_rate: float,
    warmup_steps: int
):
    """Start SFT training"""
    global model, tokenizer
    
    if training_state["is_training"]:
        return "–û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ!", "\n".join(training_state["logs"]), get_model_info()
    
    if model is None:
        return "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å!", "\n".join(training_state["logs"]), get_model_info()
    
    if not os.path.exists(data_path):
        return f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_path}", "\n".join(training_state["logs"]), get_model_info()
    
    def train_thread():
        try:
            training_state["is_training"] = True
            training_state["status"] = "–û–±—É—á–µ–Ω–∏–µ SFT..."
            log_message("–ù–∞—á–∞–ª–æ SFT –æ–±—É—á–µ–Ω–∏—è")
            
            # Create dataset
            dataset = ConversationDataset(
                data_path=data_path,
                tokenizer=tokenizer,
                max_length=config.model.max_length
            )
            
            if len(dataset) == 0:
                log_message("–û—à–∏–±–∫–∞: –¥–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç!")
                training_state["is_training"] = False
                return
            
            log_message(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
            
            # Create trainer
            trainer = SFTTrainer(
                model=model,
                tokenizer=tokenizer,
                train_dataset=dataset,
                output_dir=config.training.checkpoint_dir
            )
            
            # Train
            history = trainer.train(
                num_epochs=int(num_epochs),
                batch_size=int(batch_size),
                learning_rate=float(learning_rate),
                warmup_steps=int(warmup_steps),
                progress_callback=progress_callback
            )
            
            log_message("SFT –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            log_message(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {config.training.checkpoint_dir}")
            
        except Exception as e:
            log_message(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {str(e)}")
            log_message(traceback.format_exc())
        finally:
            training_state["is_training"] = False
            training_state["status"] = "–ì–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é"
    
    # Start training in background thread
    thread = threading.Thread(target=train_thread)
    thread.start()
    
    return "–û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ! –°–ª–µ–¥–∏—Ç–µ –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –≤ –ª–æ–≥–∞—Ö.", "\n".join(training_state["logs"]), get_model_info()


def train_dpo_handler(
    data_path: str,
    num_epochs: int,
    batch_size: int,
    learning_rate: float,
    beta: float
):
    """Start DPO training"""
    global model, tokenizer
    
    if training_state["is_training"]:
        return "–û–±—É—á–µ–Ω–∏–µ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–æ!", "\n".join(training_state["logs"]), get_model_info()
    
    if model is None:
        return "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å!", "\n".join(training_state["logs"]), get_model_info()
    
    def train_thread():
        try:
            training_state["is_training"] = True
            training_state["status"] = "–û–±—É—á–µ–Ω–∏–µ DPO..."
            log_message("–ù–∞—á–∞–ª–æ DPO –æ–±—É—á–µ–Ω–∏—è")
            
            # Create reference model (copy of current model)
            ref_model = SocialSkillsModel(
                vocab_size=model.vocab_size,
                hidden_size=model.hidden_size,
                num_layers=model.num_layers,
                num_heads=model.num_heads,
                max_length=model.max_length
            )
            ref_model.load_state_dict(model.state_dict())
            
            # Create dataset
            dataset = PreferenceDataset(
                data_path=data_path,
                tokenizer=tokenizer,
                max_length=config.model.max_length
            )
            
            if len(dataset) == 0:
                log_message("–û—à–∏–±–∫–∞: –¥–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç!")
                training_state["is_training"] = False
                return
            
            log_message(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π")
            
            # Create trainer
            trainer = DPOTrainer(
                model=model,
                ref_model=ref_model,
                tokenizer=tokenizer,
                train_dataset=dataset,
                output_dir=config.training.checkpoint_dir,
                beta=float(beta)
            )
            
            # Train
            history = trainer.train(
                num_epochs=int(num_epochs),
                batch_size=int(batch_size),
                learning_rate=float(learning_rate),
                progress_callback=progress_callback
            )
            
            log_message("DPO –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            
        except Exception as e:
            log_message(f"–û—à–∏–±–∫–∞ DPO: {str(e)}")
            log_message(traceback.format_exc())
        finally:
            training_state["is_training"] = False
            training_state["status"] = "–ì–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é"
    
    thread = threading.Thread(target=train_thread)
    thread.start()
    
    return "DPO –æ–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ!", "\n".join(training_state["logs"]), get_model_info()


def save_model_handler():
    """Save current model"""
    global model, tokenizer
    
    if model is None:
        return "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!", "\n".join(training_state["logs"])
    
    try:
        save_path = config.model.model_path
        model.save_pretrained(save_path)
        
        tokenizer_path = config.model.tokenizer_path
        os.makedirs(tokenizer_path, exist_ok=True)
        tokenizer.save_pretrained(tokenizer_path)
        
        log_message(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {save_path}")
        return f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {save_path}", "\n".join(training_state["logs"])
    
    except Exception as e:
        log_message(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")
        return f"–û—à–∏–±–∫–∞: {str(e)}", "\n".join(training_state["logs"])


def test_generation_handler(prompt: str, max_tokens: int, temperature: float):
    """Test model generation"""
    global model, tokenizer
    
    if model is None:
        return "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å!"
    
    try:
        model.eval()
        
        # Tokenize
        inputs = tokenizer(
            prompt,
            return_tensors="pt",
            truncation=True,
            max_length=config.model.max_length - max_tokens
        )
        
        device = next(model.parameters()).device
        input_ids = inputs["input_ids"].to(device)
        
        # Generate
        with torch.no_grad():
            outputs = model.generate(
                input_ids=input_ids,
                max_new_tokens=int(max_tokens),
                temperature=float(temperature),
                top_p=0.9,
                top_k=50
            )
        
        # Decode
        generated = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        return generated
    
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"


def get_training_status():
    """Get current training status"""
    status = f"""
**–°—Ç–∞—Ç—É—Å:** {training_state['status']}
**–û–±—É—á–µ–Ω–∏–µ:** {'–î–∞' if training_state['is_training'] else '–ù–µ—Ç'}
**–ü—Ä–æ–≥—Ä–µ—Å—Å:** {training_state['progress']}%
**–®–∞–≥:** {training_state['current_step']} / {training_state['total_steps']}
**Loss:** {training_state['loss']:.4f}
"""
    return status


def refresh_logs():
    """Refresh logs display"""
    return "\n".join(training_state["logs"][-50:])


def refresh_status():
    """Refresh all status displays"""
    return (
        get_training_status(),
        "\n".join(training_state["logs"][-50:]),
        get_model_info()
    )


# Build Gradio Interface
def create_interface():
    """Create Gradio interface"""
    
    with gr.Blocks(
        title="Social Skills Model Training",
        theme=gr.themes.Soft()
    ) as interface:
        
        gr.Markdown("""
        # üéØ Social Skills Model - Training Interface
        
        –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤ –Ω–∞ PyTorch.
        """)
        
        with gr.Row():
            with gr.Column(scale=2):
                # Model Info
                with gr.Group():
                    gr.Markdown("### üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")
                    model_info = gr.Markdown(get_model_info())
                    
                    with gr.Row():
                        load_btn = gr.Button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å", variant="primary")
                        save_btn = gr.Button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å")
                
                # Training Status
                with gr.Group():
                    gr.Markdown("### üìà –°—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è")
                    status_display = gr.Markdown(get_training_status())
                    refresh_btn = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å")
            
            with gr.Column(scale=3):
                # Logs
                with gr.Group():
                    gr.Markdown("### üìã –õ–æ–≥–∏")
                    logs_display = gr.Textbox(
                        value="",
                        lines=15,
                        max_lines=20,
                        label="",
                        interactive=False
                    )
        
        with gr.Tabs():
            # SFT Training Tab
            with gr.Tab("üéì SFT –û–±—É—á–µ–Ω–∏–µ"):
                gr.Markdown("""
                **Supervised Fine-Tuning** - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö –¥–∏–∞–ª–æ–≥–æ–≤.
                –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö: JSONL —Å –ø–æ–ª—è–º–∏ `instruction`, `input`, `output`.
                """)
                
                with gr.Row():
                    sft_data_path = gr.Textbox(
                        label="–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º",
                        value="./data/train/sft_data.jsonl",
                        placeholder="–ü—É—Ç—å –∫ JSONL —Ñ–∞–π–ª—É"
                    )
                
                with gr.Row():
                    sft_epochs = gr.Slider(1, 10, value=3, step=1, label="–≠–ø–æ—Ö–∏")
                    sft_batch = gr.Slider(1, 32, value=4, step=1, label="Batch Size")
                    sft_lr = gr.Number(value=2e-5, label="Learning Rate")
                    sft_warmup = gr.Slider(0, 1000, value=100, step=10, label="Warmup Steps")
                
                with gr.Row():
                    create_data_btn = gr.Button("üìù –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
                    train_sft_btn = gr.Button("üöÄ –ù–∞—á–∞—Ç—å SFT –æ–±—É—á–µ–Ω–∏–µ", variant="primary")
                
                sft_result = gr.Textbox(label="–†–µ–∑—É–ª—å—Ç–∞—Ç", lines=2)
            
            # DPO Training Tab
            with gr.Tab("‚öñÔ∏è DPO –û–±—É—á–µ–Ω–∏–µ"):
                gr.Markdown("""
                **Direct Preference Optimization** - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö.
                –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö: JSONL —Å –ø–æ–ª—è–º–∏ `prompt`, `chosen`, `rejected`.
                """)
                
                with gr.Row():
                    dpo_data_path = gr.Textbox(
                        label="–ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º",
                        value="./data/train/preference_data.jsonl",
                        placeholder="–ü—É—Ç—å –∫ JSONL —Ñ–∞–π–ª—É"
                    )
                
                with gr.Row():
                    dpo_epochs = gr.Slider(1, 5, value=1, step=1, label="–≠–ø–æ—Ö–∏")
                    dpo_batch = gr.Slider(1, 16, value=2, step=1, label="Batch Size")
                    dpo_lr = gr.Number(value=1e-5, label="Learning Rate")
                    dpo_beta = gr.Slider(0.01, 0.5, value=0.1, step=0.01, label="Beta")
                
                train_dpo_btn = gr.Button("üöÄ –ù–∞—á–∞—Ç—å DPO –æ–±—É—á–µ–Ω–∏–µ", variant="primary")
                dpo_result = gr.Textbox(label="–†–µ–∑—É–ª—å—Ç–∞—Ç", lines=2)
            
            # Test Tab
            with gr.Tab("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"):
                gr.Markdown("### –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏")
                
                test_prompt = gr.Textbox(
                    label="–ü—Ä–æ–º–ø—Ç",
                    value="–ö–∞–∫ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ —Å–ª–æ–∂–Ω–æ–º—É —Ä–∞–∑–≥–æ–≤–æ—Ä—É —Å –Ω–∞—á–∞–ª—å–Ω–∏–∫–æ–º?",
                    lines=3
                )
                
                with gr.Row():
                    test_max_tokens = gr.Slider(50, 500, value=200, label="Max Tokens")
                    test_temp = gr.Slider(0.1, 1.5, value=0.7, step=0.1, label="Temperature")
                
                test_btn = gr.Button("üîÆ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", variant="primary")
                test_output = gr.Textbox(label="–†–µ–∑—É–ª—å—Ç–∞—Ç", lines=10)
            
            # Config Tab
            with gr.Tab("‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"):
                gr.Markdown("### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –∏ –æ–±—É—á–µ–Ω–∏—è")
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("**–ú–æ–¥–µ–ª—å**")
                        cfg_hidden = gr.Number(value=config.model.hidden_size, label="Hidden Size")
                        cfg_layers = gr.Number(value=config.model.num_layers, label="Num Layers")
                        cfg_heads = gr.Number(value=config.model.num_heads, label="Num Heads")
                        cfg_vocab = gr.Number(value=config.model.vocab_size, label="Vocab Size")
                    
                    with gr.Column():
                        gr.Markdown("**–ì–µ–Ω–µ—Ä–∞—Ü–∏—è**")
                        cfg_temp = gr.Slider(0.1, 2.0, value=config.model.temperature, label="Temperature")
                        cfg_top_p = gr.Slider(0.1, 1.0, value=config.model.top_p, label="Top P")
                        cfg_top_k = gr.Slider(1, 100, value=config.model.top_k, label="Top K")
                
                gr.Markdown("""
                **–ü—É—Ç–∏:**
                - –ú–æ–¥–µ–ª—å: `{}`
                - –ß–µ–∫–ø–æ–∏–Ω—Ç—ã: `{}`
                - –î–∞–Ω–Ω—ã–µ: `{}`
                """.format(
                    config.model.model_path,
                    config.training.checkpoint_dir,
                    config.data_dir
                ))
        
        # Event handlers
        load_btn.click(
            load_model_handler,
            outputs=[model_info, logs_display]
        )
        
        save_btn.click(
            save_model_handler,
            outputs=[sft_result, logs_display]
        )
        
        refresh_btn.click(
            refresh_status,
            outputs=[status_display, logs_display, model_info]
        )
        
        create_data_btn.click(
            create_sample_data_handler,
            outputs=[logs_display]
        )
        
        train_sft_btn.click(
            train_sft_handler,
            inputs=[sft_data_path, sft_epochs, sft_batch, sft_lr, sft_warmup],
            outputs=[sft_result, logs_display, model_info]
        )
        
        train_dpo_btn.click(
            train_dpo_handler,
            inputs=[dpo_data_path, dpo_epochs, dpo_batch, dpo_lr, dpo_beta],
            outputs=[dpo_result, logs_display, model_info]
        )
        
        test_btn.click(
            test_generation_handler,
            inputs=[test_prompt, test_max_tokens, test_temp],
            outputs=[test_output]
        )
        
        # Auto-refresh logs every 2 seconds during training
        interface.load(
            refresh_logs,
            outputs=[logs_display],
            every=2
        )
    
    return interface


# Main entry point
if __name__ == "__main__":
    print("üöÄ Starting Social Skills Model Training Interface...")
    print(f"   Device: {config.training.device}")
    print(f"   GPU Available: {torch.cuda.is_available()}")
    
    interface = create_interface()
    interface.launch(
        server_name=config.gradio_host,
        server_port=config.gradio_port,
        share=False,
        inbrowser=True
    )
